# Gemini Code Assist Style Guide

<!-- âš ï¸  SYNC WARNING: Content duplicated from AI_DOCS/ -->
<!-- Gemini styleguide.md does NOT support file references -->
<!-- When AI_DOCS/ changes, manually update this file -->
<!-- Shared docs location: AI_DOCS/tdd-workflow.md, AI_DOCS/ai-tools.md, AI_DOCS/code-conventions.md, AI_DOCS/project-context.md -->

## STOP! READ THIS FIRST - MANDATORY SESSION MANAGEMENT

**BEFORE doing ANYTHING in this session, you MUST run:**

```bash
uv run ai-start-task "Your task description"
```

**If you have NOT run this command yet, STOP NOW and run it!**

This is NOT optional. Every Gemini session MUST start with `ai-start-task`.

**During work:**
```bash
uv run ai-log "Progress message"
uv run ai-update-plan "Completed item"
```

**When finishing:**
```bash
uv run ai-finish-task --summary="What you accomplished"
```

See `AI_DOCS/ai-tools.md` for complete workflow.

---

## CRITICAL: No Decorative Emojis

**NEVER use decorative emojis in any output.**

### Prohibited (Decorative)
- Section markers: ğŸš€ ğŸ¯ ğŸ³ ğŸ› ï¸ ğŸ“¦ ğŸ“š ğŸ¤– ğŸ”§ ğŸ“ ğŸ¨ ğŸ” ğŸ“
- Callouts: ğŸ‘‹ ğŸ“– ğŸ“ ğŸ“§ ğŸ‘‰ ğŸ’¡ âš¡ ğŸ”¥
- Celebrations: âœ¨ ğŸ‰ â¤ï¸ ğŸ’ª ğŸ‘
- Status: ğŸš« âš ï¸ ğŸ“¢ ğŸŠ

### Allowed (Functional Only)
- âœ… Checkboxes for completion status
- âŒ X-marks for failed/not-included items

### Applies To
- Code output (print statements, CLI messages, logs)
- Documentation (README, guides, docstrings, comments)
- Commit messages and PR descriptions
- Error messages and user-facing text
- File contents generated by code

### Rationale
- Professional appearance for enterprise use
- Universal compatibility across terminals/editors
- Better accessibility for screen readers
- Consistent with Atyantik branding standards
- Reduces visual clutter, improves readability

### Examples

**Code Output:**
```python
# âŒ WRONG
print("ğŸš€ Starting process...")
print("âœ¨ Success!")

# âœ… CORRECT
print("Starting process...")
print("Success!")
```

**Documentation:**
```markdown
âŒ WRONG: ## ğŸ¯ Quick Start
âœ… CORRECT: ## Quick Start

âŒ WRONG: **ğŸ‘‹ Welcome!** Check out the docs ğŸ“–
âœ… CORRECT: **Welcome!** Check out the docs
```

**Commit Messages:**
```bash
âŒ WRONG: "âœ¨ Add new feature ğŸš€"
âœ… CORRECT: "Add user authentication feature"
```

## CRITICAL: AI-Generated Summaries Location

**ALWAYS store AI-generated summaries in `.ai-summary/` directory.**

### Rules
- All automated AI execution summaries MUST go in `.ai-summary/`
- This directory is in `.gitignore` - never commit AI summaries
- Examples: session summaries, execution logs, automated reports
- Keeps git history clean and focused on actual code changes

### Examples

**Correct:**
```bash
# AI writes summary to proper location
.ai-summary/session-2025-11-02.md
.ai-summary/execution-log-20251102-143022.md
```

**Wrong:**
```bash
# âŒ Never write summaries to root or other directories
./ai-summary.md
./session-notes.md
docs/ai-output.md
```

### Why This Matters
- Prevents accidental commits of AI-generated content
- Keeps repository professional and focused
- Separates code from AI tool artifacts
- Consistent across all AI assistants

## CRITICAL: Git Commits - No AI Co-Authoring

**NEVER add AI co-author attribution to git commits.**

### Rules
- Do NOT add "Co-Authored-By: Claude" or any AI assistant attribution
- Do NOT add "Generated with [AI Tool]" footers
- Keep commit messages professional and human-authored
- Commits should reflect the human developer's work, not AI involvement

### Examples

**Correct:**
```bash
git commit -m "Add user authentication feature

Implemented OAuth2 authentication with JWT tokens.
Added login, logout, and token refresh endpoints.
Includes comprehensive tests with 95% coverage."
```

**Wrong:**
```bash
# âŒ Never add AI attribution
git commit -m "Add user authentication feature

...

Generated with Claude Code.

Co-Authored-By: Claude <noreply@anthropic.com>"
```

### Why This Matters
- Commits should represent human intent and responsibility
- Professional git history without AI attribution
- Clear accountability for code changes
- Industry standard practice

---

## Overview

> **Primary configuration file for Google Gemini Code Assist**
>
> This file (`.gemini/styleguide.md`) is used by Gemini Code Assist for code reviews.
> Teams can describe custom instructions here to tailor Gemini's code reviews to the repository's needs.

**Primary Directive:** Write tests BEFORE code. Use TDD (Test-Driven Development) always.

## Shared Documentation

For complete guidelines, see these shared documents in the project:

- `AI_DOCS/ai-tools.md` - Session management (MANDATORY workflow)
- `AI_DOCS/tdd-workflow.md` - TDD process and testing standards
- `AI_DOCS/code-conventions.md` - Code style and best practices
- `AI_DOCS/project-context.md` - Tech stack and architecture

**Note**: This file contains essential excerpts. For comprehensive details, read the files above.

## Core Responsibilities

1. **Test-Driven Development** - Write failing tests first
2. **Quality First** - Run `make check` before completing tasks
3. **Real Code Over Mocks** - Minimize test fixtures and mocks
4. **Type Safety** - Add type hints to all functions (mypy strict mode)
5. **Documentation Sync** - Update all AI instruction files for critical changes

See `AGENTS.md` for comprehensive universal instructions that apply to all AI agents.

## Gemini-Specific TDD Workflow

### Step-by-Step Process

**User Request Example:** "Add a function to reverse a string"

### Your Implementation:

#### 1. First, Write the Test
```python
# File: tests/test_string_utils.py

from {{ package_name }}.string_utils import reverse_string

def test_reverse_string_basic() -> None:
    """Test basic string reversal."""
    assert reverse_string("hello") == "olleh"

def test_reverse_string_empty() -> None:
    """Test reversing empty string."""
    assert reverse_string("") == ""

def test_reverse_string_single_char() -> None:
    """Test reversing single character."""
    assert reverse_string("a") == "a"

def test_reverse_string_with_spaces() -> None:
    """Test reversing string with spaces."""
    assert reverse_string("hello world") == "dlrow olleh"
```

#### 2. Run Tests (They Will Fail)
```bash
make test
# Expected: ImportError or ModuleNotFoundError
```

#### 3. Implement the Function
```python
# File: src/{{ package_name }}/string_utils.py

def reverse_string(text: str) -> str:
    """Reverse the given string.

    Args:
        text: The string to reverse

    Returns:
        The reversed string
    """
    return text[::-1]
```

#### 4. Export from __init__.py
```python
# File: src/{{ package_name }}/__init__.py

from .string_utils import reverse_string

__all__ = [..., "reverse_string"]
```

#### 5. Run Tests (Should Pass Now)
```bash
make test
# All tests should pass
```

#### 6. Run Quality Checks
```bash
make check
# This runs: format â†’ lint â†’ test
# All must pass!
```

#### 7. Report to User
"Implemented `reverse_string` using TDD:
- âœ… Wrote 4 test cases first
- âœ… Tests failed initially (function didn't exist)
- âœ… Implemented function
- âœ… All tests now pass
- âœ… `make check` passes with 100% quality
- âœ… Handles edge cases: empty strings, single chars, spaces"

## Don't Mock Internal Code

### âŒ Bad Approach (Over-Mocking)
```python
from unittest.mock import patch

@patch('{{ package_name }}.utils.helper_function')
def test_main_function(mock_helper):
    """Testing with unnecessary mock."""
    mock_helper.return_value = "mocked"
    result = main_function()
    assert result == "mocked"
```

### âœ… Good Approach (Use Real Code)
```python
from {{ package_name }}.utils import helper_function
from {{ package_name }}.main import main_function

def test_main_function() -> None:
    """Testing with real helper function."""
    # Use actual implementation
    result = main_function()
    # Test against real behavior
    assert isinstance(result, str)
    assert len(result) > 0
```

### When to Mock
Only mock:
- âœ… External APIs (HTTP requests)
- âœ… Database connections
- âœ… File system operations
- âœ… Current time/dates
- âœ… Random number generation
- âœ… Environment variables

## Code Quality Standards

### Type Hints Required
```python
# âœ… Correct - all types specified
def process_data(
    input_str: str,
    options: dict[str, Any] | None = None,
    max_length: int = 100,
) -> list[str]:
    """Process input data with options."""
    ...

# âŒ Wrong - no type hints
def process_data(input_str, options=None, max_length=100):
    ...
```

### Formatting Standards
- **Line length**: 88 characters (Black)
- **Imports**: Sorted with isort
- **Quotes**: Double quotes preferred
- **Docstrings**: Google style

### Quality Checks
```bash
# Run before finishing ANY task
make check

# Individual checks
make format    # Black + isort
make lint      # Ruff + mypy + Pylint
make test      # Pytest with coverage
make coverage  # Detailed coverage report
```

## Coverage Requirements

- **Minimum**: 80% (enforced by pytest)
- **Target**: 90%+
- **Ideal**: 100% for new code

### Check Coverage
```bash
make coverage
# Review terminal output and htmlcov/index.html
```

### If Coverage Low
Add tests for uncovered lines:
```python
def test_edge_case_branch() -> None:
    """Test the specific branch that wasn't covered."""
    # Test the specific condition
    result = function_under_test(edge_case_input)
    assert result == expected_for_edge_case
```

## Project Structure

```
src/{{ package_name }}/
  â”œâ”€â”€ __init__.py          # Package exports
  â”œâ”€â”€ main.py              # CLI implementation
  â””â”€â”€ [modules].py         # Feature modules

tests/
  â”œâ”€â”€ conftest.py          # Shared fixtures (minimal use)
  â”œâ”€â”€ test_main.py         # Tests for main.py
  â””â”€â”€ test_[module].py     # Tests for each module
```

### Import Pattern
```python
# âœ… Correct
from {{ package_name }} import function_name

# âŒ Wrong
from src.{{ package_name }} import function_name
```

## Keeping Documentation in Sync

### When to Update All AI Instruction Files

Update these files together for critical changes:
- `.cursorrules`
- `AGENTS.md`
- `.claude/INSTRUCTIONS.md`
- `GEMINI.md` (this file)
- `.aider.conf.yml`
- `COPILOT_INSTRUCTIONS.md`

**Critical changes:**
- New testing patterns
- Build/deploy process changes
- Security requirements
- Architecture decisions
- Code quality rules

### Validation
```bash
make validate-ai-docs
```

## Available Commands

```bash
# Setup
make install           # Install deps + pre-commit hooks
uv pip install -e .    # Install package in editable mode

# Development
make test              # Run tests
make coverage          # Tests with coverage report
make format            # Auto-format (Black + isort)
make lint              # Lint (Ruff + mypy + Pylint)
make check             # Complete quality check â­

# Maintenance
make clean             # Remove generated files
make build             # Build distribution package

# Help
make help              # Show all commands
```

## Pre-Commit Checklist

Before saying "task complete", verify:

- [ ] Wrote tests FIRST (TDD)
- [ ] Tests initially failed
- [ ] Implementation makes tests pass
- [ ] Used real code (not mocks) where possible
- [ ] Type hints on all functions
- [ ] Docstrings on public functions
- [ ] `make test` passes
- [ ] Coverage â‰¥ 80%
- [ ] `make check` passes
- [ ] No duplicate code (DRY)
- [ ] README updated (if needed)
- [ ] AI docs synced (if critical change)

## Security

- Never commit secrets/credentials
- Use environment variables for config
- CI runs Bandit + Safety automatically
- Fix security warnings immediately

## Best Practices for Gemini

### Small, Focused Commits
Each feature should:
1. Have tests written first
2. Implement minimal code to pass tests
3. Pass all quality checks
4. Be a logical unit of work

### Communicate Clearly
```markdown
**Implementing [Feature] with TDD:**

1. âœ… Writing tests first...
   - test_basic_case
   - test_edge_case_1
   - test_edge_case_2

2. âœ… Tests fail (as expected - function doesn't exist)

3. âœ… Implementing function...

4. âœ… Tests now pass

5. âœ… Running make check...
   - Format: PASS
   - Lint: PASS
   - Tests: PASS (95% coverage)

**Task complete!** All quality gates passed.
```

### Handle Errors Gracefully
If `make check` fails:
```markdown
**Issue found during quality check:**
- Pylint: Unused variable on line 45
- Coverage: 78% (below 80% minimum)

**Fixing:**
1. Removed unused variable
2. Added tests for uncovered branch

**Re-running make check:** âœ… All pass
```

## Example Complete Flow

**User:** "Add validation for phone numbers"

**Gemini Response:**

"I'll implement phone number validation using TDD. Writing tests first..."

```python
# Step 1: tests/test_validators.py
import pytest
from {{ package_name }}.validators import validate_phone

class TestPhoneValidation:
    """Test phone number validation."""

    @pytest.mark.parametrize(
        "phone,expected",
        [
            ("123-456-7890", True),
            ("(123) 456-7890", True),
            ("1234567890", True),
            ("123-456-789", False),  # Too short
            ("abc-def-ghij", False),  # Non-numeric
            ("", False),  # Empty
        ],
    )
    def test_phone_formats(self, phone: str, expected: bool) -> None:
        """Test various phone number formats."""
        assert validate_phone(phone) == expected
```

"Running tests - they fail as expected..."
```bash
make test
# ImportError: cannot import name 'validate_phone'
```

"Implementing function..."
```python
# src/{{ package_name }}/validators.py
import re

def validate_phone(phone: str) -> bool:
    """Validate a US phone number.

    Args:
        phone: Phone number to validate

    Returns:
        True if valid, False otherwise
    """
    # Remove formatting characters
    digits = re.sub(r'[^0-9]', '', phone)

    # Check if exactly 10 digits
    return len(digits) == 10
```

"Running tests..."
```bash
make test
# âœ… All 6 tests pass
```

"Running complete quality check..."
```bash
make check
# âœ… Format: PASS
# âœ… Lint: PASS (Pylint 10/10)
# âœ… Tests: PASS (coverage 92%)
```

"**Phone validation implemented successfully:**
- âœ… Wrote 6 parametrized tests first (TDD)
- âœ… Tests failed initially
- âœ… Implemented validation function
- âœ… All tests pass
- âœ… `make check` passes
- âœ… Handles multiple formats and edge cases
- âœ… Coverage: 92%"

## Additional Resources

- **Universal guidelines**: `AGENTS.md`
- **Cursor-specific**: `.cursorrules`
- **Claude-specific**: `.claude/INSTRUCTIONS.md`
- **Aider-specific**: `.aider.conf.yml`
- **Copilot-specific**: `COPILOT_INSTRUCTIONS.md`

---

**Required for all tasks:** Write tests first, run `make check` before completing, use real code instead of mocks.
